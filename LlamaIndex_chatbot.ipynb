{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52cb70e6-beb3-435d-a156-2eeb1c2b7156",
   "metadata": {},
   "source": [
    "**Building a ChatBot with Llamaindex**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15e184b7-67d8-481a-9636-80968c87542a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install -q -U llama-index llama-index-llms-groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c013f34-8166-4d78-8c15-988ac6d444b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from llama_index.core.llms import ChatMessage,MessageRole\n",
    "from llama_index.llms.groq import Groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "741bef9b-df43-41f4-aa08-05e10b6dbf7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"GROQ_API_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fec0fcc2-d8cc-4ba0-ba84-cdb86bc9a421",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = Groq(\n",
    "    model = \"llama-3.3-70b-versatile\",\n",
    "    temperature=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f800eb32-358e-4862-a0af-26ec9eb132e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat():\n",
    "    history = [\n",
    "        ChatMessage(role=MessageRole.SYSTEM,content=\"Your are a helpful ChatBot. Be concise and accurate\")\n",
    "    ]\n",
    "\n",
    "    print(\"LlamaIndex chat bot. type 'exit' to quit\\n\")\n",
    "\n",
    "    while True:\n",
    "        user_input = input(\"You : \").strip()\n",
    "        if user_input.lower() == 'exit':\n",
    "            break\n",
    "\n",
    "        # add a user message\n",
    "        history.append(ChatMessage(role=MessageRole.USER,content=user_input))\n",
    "      \n",
    "\n",
    "        # get response for user query\n",
    "        response = llm.chat(messages=history)\n",
    "        answer = response.message.content\n",
    "\n",
    "        # show and save assistant response\n",
    "        print(f\"Bot: {answer}\\n\")\n",
    "\n",
    "        history.append(ChatMessage(role=MessageRole.ASSISTANT,content=answer))\n",
    "\n",
    "        print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d96d4382-4a4b-4ef5-a1d1-f069b7be2d2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LlamaIndex chat bot. type 'exit' to quit\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You :  hi\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: Hi, how can I help you today?\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You :  exit\n"
     ]
    }
   ],
   "source": [
    "chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03929c66-b813-4f7e-a3c6-fb2d939bffe2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
